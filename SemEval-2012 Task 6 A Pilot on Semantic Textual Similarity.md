---
annotation-target: "[[S12-1051.pdf]]"
---


>%%
>```annotation-json
>{"created":"2023-12-11T14:02:23.949Z","updated":"2023-12-11T14:02:23.949Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":601,"end":695},{"type":"TextQuoteSelector","exact":"Semantic Textual Similarity (STS) measuresthe degree of semantic equivalence betweentwo texts.","prefix":"onzalez278@ikasle.ehu.esAbstract","suffix":" This paper presents the results"}]}]}
>```
>%%
>*%%PREFIX%%onzalez278@ikasle.ehu.esAbstract%%HIGHLIGHT%% ==Semantic Textual Similarity (STS) measuresthe degree of semantic equivalence betweentwo texts.== %%POSTFIX%%This paper presents the results*
>%%LINK%%[[#^kyf3vs4rayo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kyf3vs4rayo


>%%
>```annotation-json
>{"created":"2023-12-11T15:12:37.201Z","updated":"2023-12-11T15:12:37.201Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":1705,"end":1772},{"type":"TextQuoteSelector","exact":"STS is related to both Textual Entailment(TE) and Paraphrase (PARA)","prefix":"valence between two sen-tences. ","suffix":". STS is more directlyapplicable"}]}]}
>```
>%%
>*%%PREFIX%%valence between two sen-tences.%%HIGHLIGHT%% ==STS is related to both Textual Entailment(TE) and Paraphrase (PARA)== %%POSTFIX%%. STS is more directlyapplicable*
>%%LINK%%[[#^uhcp93jtrzn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^uhcp93jtrzn


>%%
>```annotation-json
>{"created":"2023-12-11T15:14:17.774Z","updated":"2023-12-11T15:14:17.774Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":2300,"end":2422},{"type":"TextQuoteSelector","exact":" STS incorporates the notion of graded semanticsimilarity (e.g. a vehicle and a car are more similarthan a wave and a car)","prefix":"on (e.g. a vehicle is not acar),","suffix":".STS provides a unified framewor"}]}]}
>```
>%%
>*%%PREFIX%%on (e.g. a vehicle is not acar),%%HIGHLIGHT%% ==STS incorporates the notion of graded semanticsimilarity (e.g. a vehicle and a car are more similarthan a wave and a car)== %%POSTFIX%%.STS provides a unified framewor*
>%%LINK%%[[#^gmp4acgeo6|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gmp4acgeo6


>%%
>```annotation-json
>{"created":"2023-12-11T15:14:28.195Z","updated":"2023-12-11T15:14:28.195Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":1986,"end":2058},{"type":"TextQuoteSelector","exact":"assumes symmetric graded equivalence betweenthe pair of textual snippets","prefix":"differs from TE in as much asit ","suffix":". In the case of TE theequivalen"}]}]}
>```
>%%
>*%%PREFIX%%differs from TE in as much asit%%HIGHLIGHT%% ==assumes symmetric graded equivalence betweenthe pair of textual snippets== %%POSTFIX%%. In the case of TE theequivalen*
>%%LINK%%[[#^86kehqkp5mg|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^86kehqkp5mg


>%%
>```annotation-json
>{"created":"2023-12-12T10:41:15.432Z","updated":"2023-12-12T10:41:15.432Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":14624,"end":14686},{"type":"TextQuoteSelector","exact":"The final result ta-ble thus included three evaluation metrics","prefix":"he involvement of participants. ","suffix":". For thefuture we plan to analy"}]}]}
>```
>%%
>*%%PREFIX%%he involvement of participants.%%HIGHLIGHT%% ==The final result ta-ble thus included three evaluation metrics== %%POSTFIX%%. For thefuture we plan to analy*
>%%LINK%%[[#^0154k4tbcu1we|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0154k4tbcu1we


>%%
>```annotation-json
>{"created":"2023-12-12T10:41:27.072Z","updated":"2023-12-12T10:41:27.072Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":13760,"end":13819},{"type":"TextQuoteSelector","exact":"We calculated Pearson foreach evaluation dataset separately","prefix":"ubensteinand Goodenough, 1965). ","suffix":".In order to have a single Pears"}]}]}
>```
>%%
>*%%PREFIX%%ubensteinand Goodenough, 1965).%%HIGHLIGHT%% ==We calculated Pearson foreach evaluation dataset separately== %%POSTFIX%%.In order to have a single Pears*
>%%LINK%%[[#^z2qoy0hf1qa|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^z2qoy0hf1qa


>%%
>```annotation-json
>{"created":"2023-12-12T10:41:49.113Z","updated":"2023-12-12T10:41:49.113Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":13820,"end":14014},{"type":"TextQuoteSelector","exact":"In order to have a single Pearson measure for eachsystem we concatenated the gold standard (and sys-tem outputs) for all 5 datasets into a single gold stan-dard file (and single system output). ","prefix":"h evaluation dataset separately.","suffix":"The first ver-sion of the result"}]}]}
>```
>%%
>*%%PREFIX%%h evaluation dataset separately.%%HIGHLIGHT%% ==In order to have a single Pearson measure for eachsystem we concatenated the gold standard (and sys-tem outputs) for all 5 datasets into a single gold stan-dard file (and single system output).== %%POSTFIX%%The first ver-sion of the result*
>%%LINK%%[[#^lgy6pvrzyc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^lgy6pvrzyc


>%%
>```annotation-json
>{"created":"2023-12-12T10:42:08.413Z","updated":"2023-12-12T10:42:08.413Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":14948,"end":14963},{"type":"TextQuoteSelector","exact":"overall Pearson","prefix":"s de-scribed above. We will use ","suffix":" or sim-ply ALL to refer to this"}]}]}
>```
>%%
>*%%PREFIX%%s de-scribed above. We will use%%HIGHLIGHT%% ==overall Pearson== %%POSTFIX%%or sim-ply ALL to refer to this*
>%%LINK%%[[#^1v89ctc9kc1|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1v89ctc9kc1


>%%
>```annotation-json
>{"created":"2023-12-12T10:42:16.783Z","updated":"2023-12-12T10:42:16.783Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":14819,"end":14871},{"type":"TextQuoteSelector","exact":"first evaluation metric is the Pearson correla-tion ","prefix":"arman.4.1 Evaluation metricsThe ","suffix":"for the concatenation of all fiv"}]}]}
>```
>%%
>*%%PREFIX%%arman.4.1 Evaluation metricsThe%%HIGHLIGHT%% ==first evaluation metric is the Pearson correla-tion== %%POSTFIX%%for the concatenation of all fiv*
>%%LINK%%[[#^31cp572bej6|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^31cp572bej6


>%%
>```annotation-json
>{"created":"2023-12-12T10:42:34.445Z","updated":"2023-12-12T10:42:34.445Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":15004,"end":15122},{"type":"TextQuoteSelector","exact":"The second evaluation metric normalizes the out-put for each dataset separately, using the linear leastsquares method.","prefix":"ly ALL to refer to this measure.","suffix":" We concatenated the system resu"}]}]}
>```
>%%
>*%%PREFIX%%ly ALL to refer to this measure.%%HIGHLIGHT%% ==The second evaluation metric normalizes the out-put for each dataset separately, using the linear leastsquares method.== %%POSTFIX%%We concatenated the system resu*
>%%LINK%%[[#^7j6ef93aptp|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7j6ef93aptp


>%%
>```annotation-json
>{"created":"2023-12-12T10:43:27.575Z","updated":"2023-12-12T10:43:27.575Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":15314,"end":15509},{"type":"TextQuoteSelector","exact":"we transform the system scores intoX′= {x′i} in order to minimize the squared error∑i (yi −x′i)2. The linear transformation is given byx′i = xi ∗β1 + β2, where β1 and β2 are found an-alytically. ","prefix":"he system scores,respectively), ","suffix":"We refer to this measure as Norm"}]}]}
>```
>%%
>*%%PREFIX%%he system scores,respectively),%%HIGHLIGHT%% ==we transform the system scores intoX′= {x′i} in order to minimize the squared error∑i (yi −x′i)2. The linear transformation is given byx′i = xi ∗β1 + β2, where β1 and β2 are found an-alytically.== %%POSTFIX%%We refer to this measure as Norm*
>%%LINK%%[[#^q3jg2m26nv|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^q3jg2m26nv


>%%
>```annotation-json
>{"created":"2023-12-12T10:43:37.735Z","updated":"2023-12-12T10:43:37.735Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":15537,"end":15554},{"type":"TextQuoteSelector","exact":"NormalizedPearson","prefix":"ly. We refer to this measure as ","suffix":" or simply ALLnorm. This metric "}]}]}
>```
>%%
>*%%PREFIX%%ly. We refer to this measure as%%HIGHLIGHT%% ==NormalizedPearson== %%POSTFIX%%or simply ALLnorm. This metric*
>%%LINK%%[[#^9cmgewbz7et|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9cmgewbz7et


>%%
>```annotation-json
>{"created":"2023-12-12T10:43:54.696Z","updated":"2023-12-12T10:43:54.696Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":15644,"end":15742},{"type":"TextQuoteSelector","exact":"The third evaluation metric is the weighted meanof the Pearson correlations on individual datasets","prefix":"he participants, Sergio Jimenez.","suffix":".The Pearson returned for each d"}]}]}
>```
>%%
>*%%PREFIX%%he participants, Sergio Jimenez.%%HIGHLIGHT%% ==The third evaluation metric is the weighted meanof the Pearson correlations on individual datasets== %%POSTFIX%%.The Pearson returned for each d*
>%%LINK%%[[#^ure0q8byu9c|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ure0q8byu9c


>%%
>```annotation-json
>{"created":"2023-12-12T10:44:08.444Z","updated":"2023-12-12T10:44:08.444Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":15743,"end":15849},{"type":"TextQuoteSelector","exact":"The Pearson returned for each dataset is weightedaccording to the number of sentence pairs in thatdataset.","prefix":"elations on individual datasets.","suffix":" Given ri the five Pearson score"}]}]}
>```
>%%
>*%%PREFIX%%elations on individual datasets.%%HIGHLIGHT%% ==The Pearson returned for each dataset is weightedaccording to the number of sentence pairs in thatdataset.== %%POSTFIX%%Given ri the five Pearson score*
>%%LINK%%[[#^f03j9l3gw4c|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^f03j9l3gw4c


>%%
>```annotation-json
>{"created":"2023-12-12T14:20:15.756Z","updated":"2023-12-12T14:20:15.756Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":18687,"end":18888},{"type":"TextQuoteSelector","exact":"Each result is followed by the rank of the sys-tem according to the given evaluation measure. Tothe right, the Pearson score for each dataset is given.In boldface, the three best results in each column","prefix":"or each run in alphabeticorder. ","suffix":".First of all we want to stress "}]}]}
>```
>%%
>*%%PREFIX%%or each run in alphabeticorder.%%HIGHLIGHT%% ==Each result is followed by the rank of the sys-tem according to the given evaluation measure. Tothe right, the Pearson score for each dataset is given.In boldface, the three best results in each column== %%POSTFIX%%.First of all we want to stress*
>%%LINK%%[[#^08embaq8607|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^08embaq8607


>%%
>```annotation-json
>{"created":"2023-12-12T14:23:59.911Z","updated":"2023-12-12T14:23:59.911Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":19072,"end":19191},{"type":"TextQuoteSelector","exact":"The correlation for the non-MT datasets were re-ally high: the highest correlation was obtained wasfor MSRvid (0.88 r),","prefix":"measure, improving over 19 runs.","suffix":" followed by MSRpar (0.73 r)and "}]}]}
>```
>%%
>*%%PREFIX%%measure, improving over 19 runs.%%HIGHLIGHT%% ==The correlation for the non-MT datasets were re-ally high: the highest correlation was obtained wasfor MSRvid (0.88 r),== %%POSTFIX%%followed by MSRpar (0.73 r)and*
>%%LINK%%[[#^zcyusjlregf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zcyusjlregf


>%%
>```annotation-json
>{"created":"2023-12-12T14:24:26.836Z","updated":"2023-12-12T14:24:26.836Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":19239,"end":19314},{"type":"TextQuoteSelector","exact":"The results for the MT evalu-ation data are lower, (0.57 r) for SMT-eur and","prefix":"par (0.73 r)and On-WN (0.73 r). ","suffix":" (0.61r) for SMT-News. The simpl"}]}]}
>```
>%%
>*%%PREFIX%%par (0.73 r)and On-WN (0.73 r).%%HIGHLIGHT%% ==The results for the MT evalu-ation data are lower, (0.57 r) for SMT-eur and== %%POSTFIX%%(0.61r) for SMT-News. The simpl*
>%%LINK%%[[#^umab9rc8sh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^umab9rc8sh


>%%
>```annotation-json
>{"created":"2023-12-12T14:24:51.127Z","updated":"2023-12-12T14:24:51.127Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":19337,"end":19485},{"type":"TextQuoteSelector","exact":"The simple token overlap base-line, on the contrary, obtained the highest resultsfor On-WN (0.59 r), with (0.43 r) on MSRpar and(0.40 r) on MSRvid. ","prefix":"T-eur and (0.61r) for SMT-News. ","suffix":"The results for MT evaluationdat"}]}]}
>```
>%%
>*%%PREFIX%%T-eur and (0.61r) for SMT-News.%%HIGHLIGHT%% ==The simple token overlap base-line, on the contrary, obtained the highest resultsfor On-WN (0.59 r), with (0.43 r) on MSRpar and(0.40 r) on MSRvid.== %%POSTFIX%%The results for MT evaluationdat*
>%%LINK%%[[#^glff56xls08|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^glff56xls08


>%%
>```annotation-json
>{"created":"2023-12-13T08:23:15.711Z","updated":"2023-12-13T08:23:15.711Z","document":{"title":"SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity","link":[{"href":"urn:x-pdf:9661dd46ee8d8c5497db6682ca100cbc"},{"href":"vault:/Slides/IHLT/Readings/S12-1051.pdf"}],"documentFingerprint":"9661dd46ee8d8c5497db6682ca100cbc"},"uri":"vault:/Slides/IHLT/Readings/S12-1051.pdf","target":[{"source":"vault:/Slides/IHLT/Readings/S12-1051.pdf","selector":[{"type":"TextPositionSelector","start":30970,"end":31045},{"type":"TextQuoteSelector","exact":"The top scoring systems tended to use most ofthe resources and tools listed","prefix":"e used by three or less systems.","suffix":" (UKP, Takelab), withsome notabl"}]}]}
>```
>%%
>*%%PREFIX%%e used by three or less systems.%%HIGHLIGHT%% ==The top scoring systems tended to use most ofthe resources and tools listed== %%POSTFIX%%(UKP, Takelab), withsome notabl*
>%%LINK%%[[#^32tula4jznj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^32tula4jznj
