---
annotation-target: "[[2306.09346.pdf]]"
---


>%%
>```annotation-json
>{"created":"2023-12-19T01:08:28.808Z","updated":"2023-12-19T01:08:28.808Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":2696,"end":2807},{"type":"TextQuoteSelector","exact":"he precise nature of these shared elements andthe technical mechanisms that enable their transfer remainunclear","prefix":"t in the visual world.However, t","suffix":".In this paper, we seek to ident"}]}]}
>```
>%%
>*%%PREFIX%%t in the visual world.However, t%%HIGHLIGHT%% ==he precise nature of these shared elements andthe technical mechanisms that enable their transfer remainunclear== %%POSTFIX%%.In this paper, we seek to ident*
>%%LINK%%[[#^4bjck9lscbk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4bjck9lscbk


>%%
>```annotation-json
>{"created":"2023-12-19T01:10:54.493Z","updated":"2023-12-19T01:10:54.493Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":4185,"end":4456},{"type":"TextQuoteSelector","exact":" We compare unitsfrom different layers between the models while carefullynormalizing the activation maps to overcome these differ-ences. To address synonym neurons, we also apply ourmatching method on a model with itself and cluster unitstogether according to the matches","prefix":"s these are the values we match.","suffix":".We search for Rosetta Neurons a"}]}]}
>```
>%%
>*%%PREFIX%%s these are the values we match.%%HIGHLIGHT%% ==We compare unitsfrom different layers between the models while carefullynormalizing the activation maps to overcome these differ-ences. To address synonym neurons, we also apply ourmatching method on a model with itself and cluster unitstogether according to the matches== %%POSTFIX%%.We search for Rosetta Neurons a*
>%%LINK%%[[#^exa8bbgh0ro|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^exa8bbgh0ro


>%%
>```annotation-json
>{"created":"2023-12-19T01:11:06.306Z","updated":"2023-12-19T01:11:06.306Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":4457,"end":4655},{"type":"TextQuoteSelector","exact":"We search for Rosetta Neurons across eight differ-ent models: Class Supervised-ResNet50 [13], DINO-ResNet50, DINO-ViT [4], MAE [12], CLIP-ResNet50 [24],BigGAN [3], StyleGAN-2 [15], StyleGAN-XL [29].","prefix":"gether according to the matches.","suffix":" Weapply the models to the same "}]}]}
>```
>%%
>*%%PREFIX%%gether according to the matches.%%HIGHLIGHT%% ==We search for Rosetta Neurons across eight differ-ent models: Class Supervised-ResNet50 [13], DINO-ResNet50, DINO-ViT [4], MAE [12], CLIP-ResNet50 [24],BigGAN [3], StyleGAN-2 [15], StyleGAN-XL [29].== %%POSTFIX%%Weapply the models to the same*
>%%LINK%%[[#^iy8k8hjijrj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^iy8k8hjijrj


>%%
>```annotation-json
>{"created":"2023-12-19T01:11:28.655Z","updated":"2023-12-19T01:11:28.655Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":4656,"end":4810},{"type":"TextQuoteSelector","exact":"Weapply the models to the same dataset and correlate differentunits of different models. We mine the Rosetta neurons byclustering the highest correlations","prefix":"leGAN-2 [15], StyleGAN-XL [29]. ","suffix":". This results in the emer-gence"}]}]}
>```
>%%
>*%%PREFIX%%leGAN-2 [15], StyleGAN-XL [29].%%HIGHLIGHT%% ==Weapply the models to the same dataset and correlate differentunits of different models. We mine the Rosetta neurons byclustering the highest correlations== %%POSTFIX%%. This results in the emer-gence*
>%%LINK%%[[#^auiqrewa5w5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^auiqrewa5w5


>%%
>```annotation-json
>{"created":"2023-12-19T01:12:29.033Z","updated":"2023-12-19T01:12:29.033Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":5377,"end":5457},{"type":"TextQuoteSelector","exact":"The Rosetta Neurons allow us to translate from onemodel’s “language” to another.","prefix":"ergenceof non-semantic concepts.","suffix":" One particularly useful typeof "}]}]}
>```
>%%
>*%%PREFIX%%ergenceof non-semantic concepts.%%HIGHLIGHT%% ==The Rosetta Neurons allow us to translate from onemodel’s “language” to another.== %%POSTFIX%%One particularly useful typeof*
>%%LINK%%[[#^p7y79qtgqzr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^p7y79qtgqzr


>%%
>```annotation-json
>{"created":"2023-12-19T01:13:05.072Z","updated":"2023-12-19T01:13:05.072Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":5624,"end":5787},{"type":"TextQuoteSelector","exact":"By applying simple transformationsto the activation maps of the desired Rosetta Neurons andoptimizing the generator’s latent code, we demonstrate re-alistic edits.","prefix":"y visualizethe Rosetta Neurons. ","suffix":" Additionally, we demonstrate ho"}]}]}
>```
>%%
>*%%PREFIX%%y visualizethe Rosetta Neurons.%%HIGHLIGHT%% ==By applying simple transformationsto the activation maps of the desired Rosetta Neurons andoptimizing the generator’s latent code, we demonstrate re-alistic edits.== %%POSTFIX%%Additionally, we demonstrate ho*
>%%LINK%%[[#^oe5lhmm0tos|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^oe5lhmm0tos


>%%
>```annotation-json
>{"created":"2023-12-19T01:14:54.570Z","updated":"2023-12-19T01:14:54.570Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":6276,"end":6836},{"type":"TextQuoteSelector","exact":"We show the existence of Rosetta Neurons that sharethe same concepts across different models and trainingregimes.• We develop a method for matching, normalizing, andclustering activations across models. We use thismethod to curate a dictionary of visual concepts.• The Rosetta Neurons enables model-to-model trans-lation that bridges the gap between representations ingenerative and discriminative models.• We visualize the Rosetta Neurons and exploit them ashandles to demonstrate manipulations to generated im-ages that otherwise require specialized training","prefix":"s of our paper are as follows:• ","suffix":".2. Related WorkVisualizing deep"}]}]}
>```
>%%
>*%%PREFIX%%s of our paper are as follows:•%%HIGHLIGHT%% ==We show the existence of Rosetta Neurons that sharethe same concepts across different models and trainingregimes.• We develop a method for matching, normalizing, andclustering activations across models. We use thismethod to curate a dictionary of visual concepts.• The Rosetta Neurons enables model-to-model trans-lation that bridges the gap between representations ingenerative and discriminative models.• We visualize the Rosetta Neurons and exploit them ashandles to demonstrate manipulations to generated im-ages that otherwise require specialized training== %%POSTFIX%%.2. Related WorkVisualizing deep*
>%%LINK%%[[#^nxh9e0yxcri|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nxh9e0yxcri



>%%
>```annotation-json
>{"created":"2023-12-19T01:19:11.942Z","updated":"2023-12-19T01:19:11.942Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":7164,"end":7393},{"type":"TextQuoteSelector","exact":"The seminal work of Bau etal. [1, 2] took a different approach by identifying units thathave activation maps highly correlated with semantic seg-ments in corresponding images, thereby reducing the searchspace of meaningful units.","prefix":"ture representations [20], etc. ","suffix":" However, this method neces-sita"}]}]}
>```
>%%
>*%%PREFIX%%ture representations [20], etc.%%HIGHLIGHT%% ==The seminal work of Bau etal. [1, 2] took a different approach by identifying units thathave activation maps highly correlated with semantic seg-ments in corresponding images, thereby reducing the searchspace of meaningful units.== %%POSTFIX%%However, this method neces-sita*
>%%LINK%%[[#^m99mu7f1e2c|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^m99mu7f1e2c


>%%
>```annotation-json
>{"created":"2023-12-19T01:21:26.105Z","updated":"2023-12-19T01:21:26.105Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":8243,"end":8269},{"type":"TextQuoteSelector","exact":"In all of these cases, the","prefix":" underlie classifier decisions. ","suffix":"Example ImageResNet50StyleGAN-XL"}]}]}
>```
>%%
>*%%PREFIX%%underlie classifier decisions.%%HIGHLIGHT%% ==In all of these cases, the== %%POSTFIX%%Example ImageResNet50StyleGAN-XL*
>%%LINK%%[[#^9nk30obfnam|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9nk30obfnam


>%%
>```annotation-json
>{"created":"2023-12-19T01:21:33.761Z","updated":"2023-12-19T01:21:33.761Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":9056,"end":9171},{"type":"TextQuoteSelector","exact":"point where the generative and discriminative models com-municate is in the one “language” they both speak - pixels","prefix":"according tothe extracted pairs.","suffix":";which is the output of the form"}]}]}
>```
>%%
>*%%PREFIX%%according tothe extracted pairs.%%HIGHLIGHT%% ==point where the generative and discriminative models com-municate is in the one “language” they both speak - pixels== %%POSTFIX%%;which is the output of the form*
>%%LINK%%[[#^3xf6vd8uptg|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3xf6vd8uptg


>%%
>```annotation-json
>{"created":"2023-12-19T01:22:13.662Z","updated":"2023-12-19T01:22:13.662Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":9306,"end":9423},{"type":"TextQuoteSelector","exact":"we directly match neurons from pre-trainednetworks and identify correspondences between their inter-nal activations. ","prefix":"more straightfor-ward approach: ","suffix":"Moreover, as opposed to [21] and"}]}]}
>```
>%%
>*%%PREFIX%%more straightfor-ward approach:%%HIGHLIGHT%% ==we directly match neurons from pre-trainednetworks and identify correspondences between their inter-nal activations.== %%POSTFIX%%Moreover, as opposed to [21] and*
>%%LINK%%[[#^r3oyryehyvj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^r3oyryehyvj


>%%
>```annotation-json
>{"created":"2023-12-19T01:23:35.999Z","updated":"2023-12-19T01:23:35.999Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":9950,"end":10113},{"type":"TextQuoteSelector","exact":"imed to quantify the sim-ilarities between different layers of discriminative convo-lutional neural networks, focusing on identifying and pre-serving invariances. ","prefix":"al side, Kornblith et al. [17] a","suffix":"Esser, Rombach, and Ommer [9, 28"}]}]}
>```
>%%
>*%%PREFIX%%al side, Kornblith et al. [17] a%%HIGHLIGHT%% ==imed to quantify the sim-ilarities between different layers of discriminative convo-lutional neural networks, focusing on identifying and pre-serving invariances.== %%POSTFIX%%Esser, Rombach, and Ommer [9, 28*
>%%LINK%%[[#^u1tqahskej9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^u1tqahskej9


>%%
>```annotation-json
>{"created":"2023-12-19T01:26:04.170Z","updated":"2023-12-19T01:26:04.170Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":10599,"end":10702},{"type":"TextQuoteSelector","exact":"We can visualizethese responses and gain insights into how these conceptsare represented in the network","prefix":" spatial locations in an image. ","suffix":".3. MethodOur goal is to find Ro"}]}]}
>```
>%%
>*%%PREFIX%%spatial locations in an image.%%HIGHLIGHT%% ==We can visualizethese responses and gain insights into how these conceptsare represented in the network== %%POSTFIX%%.3. MethodOur goal is to find Ro*
>%%LINK%%[[#^xqqbei5lmo8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xqqbei5lmo8


>%%
>```annotation-json
>{"created":"2023-12-19T01:31:18.249Z","updated":"2023-12-19T01:31:18.249Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":10785,"end":10923},{"type":"TextQuoteSelector","exact":"Rosetta Neurons as two (or more)neurons in different models whose activations (outputs) arepositively correlated over a set of many inputs","prefix":"s a varietyof models. We define ","suffix":". Below weexplain how to find Ro"}]}]}
>```
>%%
>*%%PREFIX%%s a varietyof models. We define%%HIGHLIGHT%% ==Rosetta Neurons as two (or more)neurons in different models whose activations (outputs) arepositively correlated over a set of many inputs== %%POSTFIX%%. Below weexplain how to find Ro*
>%%LINK%%[[#^260z3gbxa9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^260z3gbxa9


>%%
>```annotation-json
>{"created":"2023-12-19T09:04:46.101Z","updated":"2023-12-19T09:04:46.101Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":6276,"end":6837},{"type":"TextQuoteSelector","exact":"We show the existence of Rosetta Neurons that sharethe same concepts across different models and trainingregimes.• We develop a method for matching, normalizing, andclustering activations across models. We use thismethod to curate a dictionary of visual concepts.• The Rosetta Neurons enables model-to-model trans-lation that bridges the gap between representations ingenerative and discriminative models.• We visualize the Rosetta Neurons and exploit them ashandles to demonstrate manipulations to generated im-ages that otherwise require specialized training.","prefix":"s of our paper are as follows:• ","suffix":"2. Related WorkVisualizing deep "}]}]}
>```
>%%
>*%%PREFIX%%s of our paper are as follows:•%%HIGHLIGHT%% ==We show the existence of Rosetta Neurons that sharethe same concepts across different models and trainingregimes.• We develop a method for matching, normalizing, andclustering activations across models. We use thismethod to curate a dictionary of visual concepts.• The Rosetta Neurons enables model-to-model trans-lation that bridges the gap between representations ingenerative and discriminative models.• We visualize the Rosetta Neurons and exploit them ashandles to demonstrate manipulations to generated im-ages that otherwise require specialized training.== %%POSTFIX%%2. Related WorkVisualizing deep*
>%%LINK%%[[#^22q2kyw3swu|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^22q2kyw3swu


>%%
>```annotation-json
>{"created":"2023-12-19T09:04:57.576Z","updated":"2023-12-19T09:04:57.576Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":4186,"end":4811},{"type":"TextQuoteSelector","exact":"We compare unitsfrom different layers between the models while carefullynormalizing the activation maps to overcome these differ-ences. To address synonym neurons, we also apply ourmatching method on a model with itself and cluster unitstogether according to the matches.We search for Rosetta Neurons across eight differ-ent models: Class Supervised-ResNet50 [13], DINO-ResNet50, DINO-ViT [4], MAE [12], CLIP-ResNet50 [24],BigGAN [3], StyleGAN-2 [15], StyleGAN-XL [29]. Weapply the models to the same dataset and correlate differentunits of different models. We mine the Rosetta neurons byclustering the highest correlations.","prefix":" these are the values we match. ","suffix":" This results in the emer-gence "}]}]}
>```
>%%
>*%%PREFIX%%these are the values we match.%%HIGHLIGHT%% ==We compare unitsfrom different layers between the models while carefullynormalizing the activation maps to overcome these differ-ences. To address synonym neurons, we also apply ourmatching method on a model with itself and cluster unitstogether according to the matches.We search for Rosetta Neurons across eight differ-ent models: Class Supervised-ResNet50 [13], DINO-ResNet50, DINO-ViT [4], MAE [12], CLIP-ResNet50 [24],BigGAN [3], StyleGAN-2 [15], StyleGAN-XL [29]. Weapply the models to the same dataset and correlate differentunits of different models. We mine the Rosetta neurons byclustering the highest correlations.== %%POSTFIX%%This results in the emer-gence*
>%%LINK%%[[#^mdf13z58xw|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mdf13z58xw


>%%
>```annotation-json
>{"created":"2023-12-19T09:05:06.619Z","updated":"2023-12-19T09:05:06.619Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":5378,"end":5457},{"type":"TextQuoteSelector","exact":"he Rosetta Neurons allow us to translate from onemodel’s “language” to another.","prefix":"rgenceof non-semantic concepts.T","suffix":" One particularly useful typeof "}]}]}
>```
>%%
>*%%PREFIX%%rgenceof non-semantic concepts.T%%HIGHLIGHT%% ==he Rosetta Neurons allow us to translate from onemodel’s “language” to another.== %%POSTFIX%%One particularly useful typeof*
>%%LINK%%[[#^dszjnfw6fjj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^dszjnfw6fjj


>%%
>```annotation-json
>{"created":"2023-12-19T09:05:26.610Z","updated":"2023-12-19T09:05:26.610Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":5624,"end":5787},{"type":"TextQuoteSelector","exact":"By applying simple transformationsto the activation maps of the desired Rosetta Neurons andoptimizing the generator’s latent code, we demonstrate re-alistic edits.","prefix":"y visualizethe Rosetta Neurons. ","suffix":" Additionally, we demonstrate ho"}]}]}
>```
>%%
>*%%PREFIX%%y visualizethe Rosetta Neurons.%%HIGHLIGHT%% ==By applying simple transformationsto the activation maps of the desired Rosetta Neurons andoptimizing the generator’s latent code, we demonstrate re-alistic edits.== %%POSTFIX%%Additionally, we demonstrate ho*
>%%LINK%%[[#^xfwultulcif|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xfwultulcif


>%%
>```annotation-json
>{"created":"2023-12-19T09:05:42.488Z","updated":"2023-12-19T09:05:42.488Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":7164,"end":7394},{"type":"TextQuoteSelector","exact":"The seminal work of Bau etal. [1, 2] took a different approach by identifying units thathave activation maps highly correlated with semantic seg-ments in corresponding images, thereby reducing the searchspace of meaningful units. ","prefix":"ture representations [20], etc. ","suffix":"However, this method neces-sitat"}]}]}
>```
>%%
>*%%PREFIX%%ture representations [20], etc.%%HIGHLIGHT%% ==The seminal work of Bau etal. [1, 2] took a different approach by identifying units thathave activation maps highly correlated with semantic seg-ments in corresponding images, thereby reducing the searchspace of meaningful units.== %%POSTFIX%%However, this method neces-sitat*
>%%LINK%%[[#^v4lyox5lif|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^v4lyox5lif


>%%
>```annotation-json
>{"created":"2023-12-19T09:06:08.638Z","updated":"2023-12-19T09:06:08.638Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":9056,"end":9172},{"type":"TextQuoteSelector","exact":"point where the generative and discriminative models com-municate is in the one “language” they both speak - pixels;","prefix":"according tothe extracted pairs.","suffix":"which is the output of the forme"}]}]}
>```
>%%
>*%%PREFIX%%according tothe extracted pairs.%%HIGHLIGHT%% ==point where the generative and discriminative models com-municate is in the one “language” they both speak - pixels;== %%POSTFIX%%which is the output of the forme*
>%%LINK%%[[#^zbhgboq8lj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zbhgboq8lj


>%%
>```annotation-json
>{"created":"2023-12-19T09:06:22.391Z","updated":"2023-12-19T09:06:22.391Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":9306,"end":9423},{"type":"TextQuoteSelector","exact":"we directly match neurons from pre-trainednetworks and identify correspondences between their inter-nal activations. ","prefix":"more straightfor-ward approach: ","suffix":"Moreover, as opposed to [21] and"}]}]}
>```
>%%
>*%%PREFIX%%more straightfor-ward approach:%%HIGHLIGHT%% ==we directly match neurons from pre-trainednetworks and identify correspondences between their inter-nal activations.== %%POSTFIX%%Moreover, as opposed to [21] and*
>%%LINK%%[[#^gcdjwsifqym|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gcdjwsifqym


>%%
>```annotation-json
>{"created":"2023-12-19T09:06:29.041Z","updated":"2023-12-19T09:06:29.041Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":9949,"end":10113},{"type":"TextQuoteSelector","exact":"aimed to quantify the sim-ilarities between different layers of discriminative convo-lutional neural networks, focusing on identifying and pre-serving invariances. ","prefix":"nal side, Kornblith et al. [17] ","suffix":"Esser, Rombach, and Ommer [9, 28"}]}]}
>```
>%%
>*%%PREFIX%%nal side, Kornblith et al. [17]%%HIGHLIGHT%% ==aimed to quantify the sim-ilarities between different layers of discriminative convo-lutional neural networks, focusing on identifying and pre-serving invariances.== %%POSTFIX%%Esser, Rombach, and Ommer [9, 28*
>%%LINK%%[[#^lvhu4c9ze6h|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^lvhu4c9ze6h


>%%
>```annotation-json
>{"created":"2023-12-19T09:06:39.163Z","updated":"2023-12-19T09:06:39.163Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":10785,"end":10923},{"type":"TextQuoteSelector","exact":"Rosetta Neurons as two (or more)neurons in different models whose activations (outputs) arepositively correlated over a set of many inputs","prefix":"s a varietyof models. We define ","suffix":". Below weexplain how to find Ro"}]}]}
>```
>%%
>*%%PREFIX%%s a varietyof models. We define%%HIGHLIGHT%% ==Rosetta Neurons as two (or more)neurons in different models whose activations (outputs) arepositively correlated over a set of many inputs== %%POSTFIX%%. Below weexplain how to find Ro*
>%%LINK%%[[#^io4rcwv52n|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^io4rcwv52n


>%%
>```annotation-json
>{"created":"2023-12-19T09:06:57.448Z","updated":"2023-12-19T09:06:57.448Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":10599,"end":10703},{"type":"TextQuoteSelector","exact":"We can visualizethese responses and gain insights into how these conceptsare represented in the network.","prefix":" spatial locations in an image. ","suffix":"3. MethodOur goal is to find Ros"}]}]}
>```
>%%
>*%%PREFIX%%spatial locations in an image.%%HIGHLIGHT%% ==We can visualizethese responses and gain insights into how these conceptsare represented in the network.== %%POSTFIX%%3. MethodOur goal is to find Ros*
>%%LINK%%[[#^hhn01dw4ngn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hhn01dw4ngn


>%%
>```annotation-json
>{"created":"2023-12-19T09:07:14.905Z","updated":"2023-12-19T09:07:14.905Z","document":{"title":"2306.09346.pdf","link":[{"href":"urn:x-pdf:16391c521e45f1a40d8a566ceaad0078"},{"href":"vault:/Slides/CV/LAB/2306.09346.pdf"}],"documentFingerprint":"16391c521e45f1a40d8a566ceaad0078"},"uri":"vault:/Slides/CV/LAB/2306.09346.pdf","target":[{"source":"vault:/Slides/CV/LAB/2306.09346.pdf","selector":[{"type":"TextPositionSelector","start":2695,"end":2808},{"type":"TextQuoteSelector","exact":"the precise nature of these shared elements andthe technical mechanisms that enable their transfer remainunclear.","prefix":"nt in the visual world.However, ","suffix":"In this paper, we seek to identi"}]}]}
>```
>%%
>*%%PREFIX%%nt in the visual world.However,%%HIGHLIGHT%% ==the precise nature of these shared elements andthe technical mechanisms that enable their transfer remainunclear.== %%POSTFIX%%In this paper, we seek to identi*
>%%LINK%%[[#^umiglm1jzd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^umiglm1jzd
